{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31884\\619078662.py:3\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mot\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. warning::\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    The list of automatically imported sub-modules is as follows:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m    - :any:`ot.plot` : depends on :code:`matplotlib`\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# Author: Remi Flamary <remi.flamary@unice.fr>\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#         Nicolas Courty <ncourty@irisa.fr>\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[39m# All submodules and packages\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m lp\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bregman\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m optim\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\lp\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcvx\u001b[39;00m \u001b[39mimport\u001b[39;00m barycenter\n\u001b[0;32m     21\u001b[0m \u001b[39m# import compiled emd\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39memd_wrap\u001b[39;00m \u001b[39mimport\u001b[39;00m emd_c, check_result, emd_1d_sorted\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msolver_1d\u001b[39;00m \u001b[39mimport\u001b[39;00m emd_1d, emd2_1d, wasserstein_1d\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m dist, list_to_array\n",
      "File \u001b[1;32mot/lp/emd_wrap.pyx:13\u001b[0m, in \u001b[0;36minit ot.lp.emd_wrap\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\utils.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minspect\u001b[39;00m \u001b[39mimport\u001b[39;00m signature\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m get_backend, Backend\n\u001b[0;32m     20\u001b[0m __time_tic_toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtic\u001b[39m():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\backend.py:98\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     torch_type \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor\n\u001b[0;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\__init__.py:798\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast\n\u001b[0;32m    797\u001b[0m \u001b[39m# Shared memory manager needs to know the exact location of manager executable\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m _C\u001b[39m.\u001b[39;49m_initExtension(manager_path())\n\u001b[0;32m    799\u001b[0m \u001b[39mdel\u001b[39;00m manager_path\n\u001b[0;32m    801\u001b[0m \u001b[39m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\cuda\\__init__.py:179\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m             \u001b[39m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[0;32m    177\u001b[0m             _queued_calls\u001b[39m.\u001b[39mappend((callable, traceback\u001b[39m.\u001b[39mformat_stack()))\n\u001b[1;32m--> 179\u001b[0m _lazy_call(_check_capability)\n\u001b[0;32m    180\u001b[0m _lazy_call(_check_cubins)\n\u001b[0;32m    183\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDeferredCudaCallError\u001b[39;00m(\u001b[39mException\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\cuda\\__init__.py:177\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m     _lazy_seed_tracker\u001b[39m.\u001b[39mqueue_seed(callable, traceback\u001b[39m.\u001b[39mformat_stack())\n\u001b[0;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[39m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     _queued_calls\u001b[39m.\u001b[39mappend((callable, traceback\u001b[39m.\u001b[39;49mformat_stack()))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m format_list(extract_stack(f, limit\u001b[39m=\u001b[39;49mlimit))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[0;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m result:\n\u001b[1;32m--> 366\u001b[0m         f\u001b[39m.\u001b[39;49mline\n\u001b[0;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39;49mgetline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineno)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetline\u001b[39m(filename, lineno, module_globals\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[39m=\u001b[39m getlines(filename, module_globals)\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lineno \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m lines[lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m cache[filename][\u001b[39m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m updatecache(filename, module_globals)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mwith\u001b[39;00m tokenize\u001b[39m.\u001b[39;49mopen(fullname) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    137\u001b[0m         lines \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\tokenize.py:392\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(filename):\n\u001b[0;32m    389\u001b[0m     \u001b[39m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[39m    detect_encoding().\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     buffer \u001b[39m=\u001b[39m _builtin_open(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    393\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m         encoding, lines \u001b[39m=\u001b[39m detect_encoding(buffer\u001b[39m.\u001b[39mreadline)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\nelsite\\Desktop\\Coding_with_Fahim\\Topological_Segmentation\\TopoSegNetSimple\\TopoSegNetSimple\\network\\Topo_treatment.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# import sys\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# # python library compile from cpp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# sys.path.insert(0, './persis_lib_cpp')\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# from persis_homo_optimal import *\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mUtility_general.ipynb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mrun\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mUtility_topo.ipynb\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/nelsite/Desktop/Coding_with_Fahim/Topological_Segmentation/TopoSegNetSimple/TopoSegNetSimple/network/Topo_treatment.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpersim\u001b[39;00m \u001b[39mimport\u001b[39;00m PersImage\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2304\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2302\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2303\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2304\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2305\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\IPython\\core\\magics\\execution.py:717\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[1;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[39mwith\u001b[39;00m preserve_keys(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    716\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m filename\n\u001b[1;32m--> 717\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49msafe_execfile_ipy(filename, raise_exceptions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    718\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    720\u001b[0m \u001b[39m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2810\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[1;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[0;32m   2808\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_cell(cell, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, shell_futures\u001b[39m=\u001b[39mshell_futures)\n\u001b[0;32m   2809\u001b[0m \u001b[39mif\u001b[39;00m raise_exceptions:\n\u001b[1;32m-> 2810\u001b[0m     result\u001b[39m.\u001b[39;49mraise_error()\n\u001b[0;32m   2811\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39msuccess:\n\u001b[0;32m   2812\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\IPython\\core\\interactiveshell.py:250\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    248\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_before_exec\n\u001b[0;32m    249\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 250\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec\n",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_31884\\619078662.py:3\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mndimage\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mot\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcopy\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m.. warning::\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m    The list of automatically imported sub-modules is as follows:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[39m    - :any:`ot.plot` : depends on :code:`matplotlib`\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m# Author: Remi Flamary <remi.flamary@unice.fr>\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m#         Nicolas Courty <ncourty@irisa.fr>\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[39m# All submodules and packages\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m lp\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m bregman\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m optim\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\lp\\__init__.py:22\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcvx\u001b[39;00m \u001b[39mimport\u001b[39;00m barycenter\n\u001b[0;32m     21\u001b[0m \u001b[39m# import compiled emd\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39memd_wrap\u001b[39;00m \u001b[39mimport\u001b[39;00m emd_c, check_result, emd_1d_sorted\n\u001b[0;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39msolver_1d\u001b[39;00m \u001b[39mimport\u001b[39;00m emd_1d, emd2_1d, wasserstein_1d\n\u001b[0;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m dist, list_to_array\n",
      "File \u001b[1;32mot/lp/emd_wrap.pyx:13\u001b[0m, in \u001b[0;36minit ot.lp.emd_wrap\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\utils.py:18\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39minspect\u001b[39;00m \u001b[39mimport\u001b[39;00m signature\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend\u001b[39;00m \u001b[39mimport\u001b[39;00m get_backend, Backend\n\u001b[0;32m     20\u001b[0m __time_tic_toc \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtic\u001b[39m():\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\ot\\backend.py:98\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[0;32m     97\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 98\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m     99\u001b[0m     torch_type \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mTensor\n\u001b[0;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\__init__.py:798\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mamp\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast\n\u001b[0;32m    797\u001b[0m \u001b[39m# Shared memory manager needs to know the exact location of manager executable\u001b[39;00m\n\u001b[1;32m--> 798\u001b[0m _C\u001b[39m.\u001b[39;49m_initExtension(manager_path())\n\u001b[0;32m    799\u001b[0m \u001b[39mdel\u001b[39;00m manager_path\n\u001b[0;32m    801\u001b[0m \u001b[39m# Appease the type checker: it can't deal with direct setting of globals().\u001b[39;00m\n\u001b[0;32m    802\u001b[0m \u001b[39m# Note that we will see \"too many\" functions when reexporting this way; there\u001b[39;00m\n\u001b[0;32m    803\u001b[0m \u001b[39m# is not a good way to fix this problem.  Perhaps, try to redesign VariableFunctions\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m# so that this import is good enough\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\cuda\\__init__.py:179\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m             \u001b[39m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[0;32m    177\u001b[0m             _queued_calls\u001b[39m.\u001b[39mappend((callable, traceback\u001b[39m.\u001b[39mformat_stack()))\n\u001b[1;32m--> 179\u001b[0m _lazy_call(_check_capability)\n\u001b[0;32m    180\u001b[0m _lazy_call(_check_cubins)\n\u001b[0;32m    183\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mDeferredCudaCallError\u001b[39;00m(\u001b[39mException\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\site-packages\\torch\\cuda\\__init__.py:177\u001b[0m, in \u001b[0;36m_lazy_call\u001b[1;34m(callable, **kwargs)\u001b[0m\n\u001b[0;32m    174\u001b[0m     _lazy_seed_tracker\u001b[39m.\u001b[39mqueue_seed(callable, traceback\u001b[39m.\u001b[39mformat_stack())\n\u001b[0;32m    175\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    176\u001b[0m     \u001b[39m# Don't store the actual traceback to avoid memory cycle\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     _queued_calls\u001b[39m.\u001b[39mappend((callable, traceback\u001b[39m.\u001b[39;49mformat_stack()))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:197\u001b[0m, in \u001b[0;36mformat_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 197\u001b[0m \u001b[39mreturn\u001b[39;00m format_list(extract_stack(f, limit\u001b[39m=\u001b[39;49mlimit))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:211\u001b[0m, in \u001b[0;36mextract_stack\u001b[1;34m(f, limit)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     f \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39m_getframe()\u001b[39m.\u001b[39mf_back\n\u001b[1;32m--> 211\u001b[0m stack \u001b[39m=\u001b[39m StackSummary\u001b[39m.\u001b[39;49mextract(walk_stack(f), limit\u001b[39m=\u001b[39;49mlimit)\n\u001b[0;32m    212\u001b[0m stack\u001b[39m.\u001b[39mreverse()\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m stack\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:366\u001b[0m, in \u001b[0;36mStackSummary.extract\u001b[1;34m(klass, frame_gen, limit, lookup_lines, capture_locals)\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[39mif\u001b[39;00m lookup_lines:\n\u001b[0;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m result:\n\u001b[1;32m--> 366\u001b[0m         f\u001b[39m.\u001b[39;49mline\n\u001b[0;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\traceback.py:288\u001b[0m, in \u001b[0;36mFrameSummary.line\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    285\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mline\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    287\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line \u001b[39m=\u001b[39m linecache\u001b[39m.\u001b[39;49mgetline(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfilename, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlineno)\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m    289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_line\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:30\u001b[0m, in \u001b[0;36mgetline\u001b[1;34m(filename, lineno, module_globals)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetline\u001b[39m(filename, lineno, module_globals\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     27\u001b[0m     \u001b[39m\"\"\"Get a line for a Python source file from the cache.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39m    Update the cache if it doesn't contain an entry for this file already.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m     lines \u001b[39m=\u001b[39m getlines(filename, module_globals)\n\u001b[0;32m     31\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m lineno \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(lines):\n\u001b[0;32m     32\u001b[0m         \u001b[39mreturn\u001b[39;00m lines[lineno \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:46\u001b[0m, in \u001b[0;36mgetlines\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[39mreturn\u001b[39;00m cache[filename][\u001b[39m2\u001b[39m]\n\u001b[0;32m     45\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 46\u001b[0m     \u001b[39mreturn\u001b[39;00m updatecache(filename, module_globals)\n\u001b[0;32m     47\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mMemoryError\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     clearcache()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\linecache.py:136\u001b[0m, in \u001b[0;36mupdatecache\u001b[1;34m(filename, module_globals)\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 136\u001b[0m     \u001b[39mwith\u001b[39;00m tokenize\u001b[39m.\u001b[39;49mopen(fullname) \u001b[39mas\u001b[39;00m fp:\n\u001b[0;32m    137\u001b[0m         lines \u001b[39m=\u001b[39m fp\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\envs\\code_with_fahim\\lib\\tokenize.py:392\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(filename):\n\u001b[0;32m    389\u001b[0m     \u001b[39m\"\"\"Open a file in read only mode using the encoding detected by\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[39m    detect_encoding().\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 392\u001b[0m     buffer \u001b[39m=\u001b[39m _builtin_open(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    393\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    394\u001b[0m         encoding, lines \u001b[39m=\u001b[39m detect_encoding(buffer\u001b[39m.\u001b[39mreadline)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# # python library compile from cpp\n",
    "# sys.path.insert(0, './persis_lib_cpp')\n",
    "# from persis_homo_optimal import *\n",
    "\n",
    "%run Utility_general.ipynb\n",
    "%run Utility_topo.ipynb\n",
    "\n",
    "from persim import PersImage\n",
    "from numpy import linalg as LA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from cvxopt import matrix, spmatrix, sparse, solvers\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # installed lib for persistence image\n",
    "# import PersistenceImages.persistence_images as pimg\n",
    "\n",
    "class Edges_(object):\n",
    "    \n",
    "    def __init__(self, params, debug=False):\n",
    "        self.pc      = Persistence_Computer()\n",
    "        self.persimg = PersImg_(params[\"persimg\"], False)\n",
    "        self.debug   = debug\n",
    "        \n",
    "        # Parse parameters\n",
    "        self.target_dim      = params[\"Topo_edge\"][\"target_topo_dimension\"]\n",
    "        self.tp_loss_weight  = params[\"Topo_edge\"][\"topology_loss_weight\"]\n",
    "        self.blind_force     = params[\"Topo_edge\"][\"use_blind_force\"]\n",
    "        self.project2dim     = params[\"Topo_edge\"][\"project_2_dim\"]\n",
    "        self.watershed       = params[\"Topo_edge\"][\"image_watershed\"]\n",
    "        self.topo_threshold  = params[\"Topo_edge\"][\"target_topo_threshold\"]\n",
    "        self.pts_to_fix      = params[\"Topo_edge\"][\"number_of_pts_to_fix\"]\n",
    "        self.hole_kernel_r   = params[\"Topo_edge\"][\"hole_test_kernel_radius\"]\n",
    "        self.hole_iterations = params[\"Topo_edge\"][\"hole_test_iteration\"]\n",
    "        self.hole_bordwidth  = params[\"Topo_edge\"][\"hole_test_border_width\"]\n",
    "        self.hole_threshold  = params[\"Topo_edge\"][\"hole_test_threshold\"]\n",
    "        \n",
    "        self.opposite2       = params[\"Topo_edge\"][\"detect_opposite_2pts\"]\n",
    "        self.connect         = params[\"Topo_edge\"][\"connect_2pts\"]\n",
    "        self.thickness       = params[\"Topo_edge\"][\"segment_thickness\"]\n",
    "        self.pd_subset_rate  = params[\"Topo_edge\"][\"pd_subset_rate\"]\n",
    "        self.shuffle_subset  = params[\"Topo_edge\"][\"shuffle_subset\"]\n",
    "        \n",
    "    def load_pd_pool(self, dir_in, ext_in, percentage, batch_size):\n",
    "        '''\n",
    "        Load in persistence diagrams pre-computed for database. Needs to be\n",
    "        called before subset_pd_pool(). Note, if self.topo_threshold > 0, \n",
    "        persistence diagram will be filtered before projection if any.\n",
    "        ===== inputs\n",
    "        percentage: percentage of database to be loaded, max 1.0\n",
    "        batch_size: number of images in each generated batch, has to be fixed all along, integer\n",
    "        project2dim: if to project 2d persistence diagram to birth or death\n",
    "        '''\n",
    "        self.set_ref, _= FileIO.read_pd_subset(dir_in, ext_in, percentage, shuffle=False, dummyifempty=True) \n",
    "        print(\"Reference persistence diagram read complete.\")\n",
    "        if self.topo_threshold > 0:\n",
    "            self.set_ref = Utility_topo.topo_filter_retmat(self.set_ref, self.topo_threshold)\n",
    "            print(\"Reference persistence diagram filter complete.\")\n",
    "        if self.project2dim >= 0:\n",
    "            assert(self.project2dim < 2)\n",
    "            self.set_ref = Utility_topo.extract_dim_from_list(self.set_ref, self.project2dim)\n",
    "            print(\"Reference persistence diagram extracted from dimension %d.\" %self.project2dim)\n",
    "            \n",
    "        self.ref_num     = len(self.set_ref)\n",
    "        self.read_num    = int(np.floor(self.ref_num * self.pd_subset_rate))\n",
    "        self.lp_         = LPSolver_(batch_size, self.read_num, False)\n",
    "        print(\"Compute wasserstein distance between %d and %d\" %(batch_size, self.read_num))\n",
    "        \n",
    "    def subset_pd_pool(self, num, read_num, shuffle=True):\n",
    "        if shuffle:\n",
    "            ind_list = random.sample(range(num), read_num)\n",
    "        else:\n",
    "            ind_list = np.arange(read_num)\n",
    "        subset = [None] * read_num\n",
    "        for i in range(read_num):\n",
    "            subset[i] = self.set_ref[ind_list[i]]\n",
    "        return subset\n",
    "    \n",
    "    def fix_with_topo(self, gen, label, dim, result_dir, batch_number, value, wassertein_dist=1.0, blind=False):\n",
    "        '''\n",
    "        ===== inputs\n",
    "        gen: generated 1-channel images from generator, should have value from -1.0 to 1.0\n",
    "        dim: dimension of the topological structures to extract\n",
    "        value: the value assigned to detected points, in range of -1.0 and 1.0\n",
    "        wassertein_dist: 1-wasserstein or 2-wasserstein distance, has to be 1.0 or 2.0\n",
    "        '''\n",
    "        \n",
    "        assert(dim == 0 or dim == 1)\n",
    "        \n",
    "        gen_bin   = Utility_topo.binarize_data(gen, self.watershed)\n",
    "        print(\"pred_bin\")\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(12, 4))\n",
    "        for i in range(5):\n",
    "            gen_bin[i][gen_bin[i] == 0] = 1\n",
    "            gen_bin[i][gen_bin[i] == 255] = 0\n",
    "            ax[i].imshow(gen_bin[i], cmap='gray')\n",
    "            ax[i].axis('off')\n",
    "            \n",
    "        plt.savefig(f\"{result_dir}_batch{batch_number}_pred_binary.png\")\n",
    "        plt.show()\n",
    "        #print(\"gen_bin max :\",  gen_bin.max())\n",
    "        #print(\"gen_bin min :\",  gen_bin.min())\n",
    "        #plt.imshow(gen_bin)\n",
    "        tsfm_list = Utility_topo.dist_trfm_batch(gen_bin)\n",
    "        print(\"pred_tsfm_list\")\n",
    "        \n",
    "        arr_list_2d = [arr.reshape((64, 64)) for arr in tsfm_list]\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(12, 4))\n",
    "        for i in range(5):\n",
    "            ax[i].imshow(arr_list_2d[i], cmap='gray')\n",
    "            ax[i].axis('off')\n",
    "        \n",
    "        plt.savefig(f\"{result_dir}_batch{batch_number}_pred_tsfm_list.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        label_bin   = Utility_topo.binarize_data(label, self.watershed)\n",
    "        print(\"label_bin\")\n",
    "\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(12, 4))\n",
    "        for i in range(5):\n",
    "            label_bin[i][label_bin[i] == 0] = 1\n",
    "            label_bin[i][label_bin[i] == 255] = 0\n",
    "            ax[i].imshow(gen_bin[i], cmap='gray')\n",
    "            ax[i].axis('off')\n",
    "            \n",
    "        plt.savefig(f\"{result_dir}_batch{batch_number}_label_binary.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        tsfm_list2 = Utility_topo.dist_trfm_batch(label_bin)\n",
    "        print(\"label_tsfm_list\")\n",
    "        \n",
    "        arr_list_2d_label = [arr.reshape((64, 64)) for arr in tsfm_list2]\n",
    "        fig, ax = plt.subplots(nrows=1, ncols=5, figsize=(12, 4))\n",
    "        for i in range(5):\n",
    "            ax[i].imshow(arr_list_2d_label[i], cmap='gray')\n",
    "            ax[i].axis('off')\n",
    "        \n",
    "        plt.savefig(f\"{result_dir}_batch{batch_number}_label_tsfm_list.png\")\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "        if dim == 0:\n",
    "            B, D, set1, _, red1 = Utility_topo.compute_dist_homology(gen_bin.shape,\n",
    "                         tsfm_list, self.pc, dim, debug=True, old_form=False)\n",
    "        else:\n",
    "            B, D, set1 = Utility_topo.compute_dist_homology(gen_bin.shape,\n",
    "                     tsfm_list, self.pc, dim, debug=False, old_form=False)\n",
    "            \n",
    "        \n",
    "        if dim == 0:\n",
    "            B2, D2, set2, _, red2 = Utility_topo.compute_dist_homology(label_bin.shape,\n",
    "                         tsfm_list2, self.pc, dim, debug=True, old_form=False)\n",
    "        else:\n",
    "            B2, D2, set2 = Utility_topo.compute_dist_homology(label_bin.shape,\n",
    "                     tsfm_list2, self.pc, dim, debug=False, old_form=False)\n",
    "        \n",
    "        if self.project2dim >= 0:\n",
    "            set1 = Utility_topo.extract_dim_from_list(set1, self.project2dim)\n",
    "            set2 = Utility_topo.extract_dim_from_list(set2, self.project2dim)\n",
    "        \n",
    "        print(\"set1 :\", set1)\n",
    "        print(\"set2 :\", set2)\n",
    "        dist, G = Utility_general.wasserstein_set_distance(set1, set2, wassertein_dist)\n",
    "        #print(\"set1 after : \", set1)\n",
    "        \n",
    "        self.read_set1_size     = len(set1)\n",
    "        #print(\"set1 size:\", set1[0].size)\n",
    "        self.read_set2_size     = len(set2)\n",
    "        #print(\"set2 size:\", set2[0].size)\n",
    "        self.lp_test = LPSolver_(self.read_set1_size, self.read_set2_size, False)\n",
    "        \n",
    "        mapping, dist, G = self.lp_test.linear_program_(dist, G)\n",
    "        force = Utility_topo.topo_force_(set1, set2, G, mapping)\n",
    "        mean_wasserstein_dist = np.mean(np.asarray(dist))\n",
    "        \n",
    "        \n",
    "            \n",
    "        '''if self.topo_threshold > 0:\n",
    "            if dim == 0:\n",
    "                print(\"Dim 0 with topology threshold > 0 detected.\")\n",
    "                red1 = Utility_topo.topo_filter_retmat_bndorred_mul(red1, set1, self.topo_threshold)\n",
    "            B, D, set1 = Utility_topo.topo_filter_retmat_mul(B, D, set1, self.topo_threshold)\n",
    "        if self.project2dim >= 0:\n",
    "            set1 = Utility_topo.extract_dim_from_list(set1, self.project2dim)\n",
    "        if blind:\n",
    "            force = Utility_topo.topo_force_blind_(set1, dim)\n",
    "            mean_wasserstein_dist = -1.0\n",
    "        else:\n",
    "            set2 = self.subset_pd_pool(self.ref_num, self.read_num, self.shuffle_subset)\n",
    "            dist, G = Utility_general.wasserstein_set_distance(set1, set2, wassertein_dist)\n",
    "            mapping, dist, G = self.lp_.linear_program_(dist, G)\n",
    "            force = Utility_topo.topo_force_(set1, set2, G, mapping)\n",
    "            mean_wasserstein_dist = np.mean(np.asarray(dist))'''\n",
    "\n",
    "        if dim == 0:\n",
    "            flt_lst, frc_x_, frc_y_ = Utility_topo.apply_force_dim0_(force, red1, False)\n",
    "        else:\n",
    "            bnd_cv, hcy_cv, red_cv  = Utility_topo.compute_bnd_red_cv_batch(gen_bin)\n",
    "            flt_lst, frc_x_, frc_y_ = Utility_topo.apply_force_(set1, force, B, bnd_cv, hcy_cv, self.pts_to_fix,\n",
    "                                      False, self.opposite2, self.connect, gen_bin.shape[1:], self.thickness)\n",
    "        gen_res = self.plot_on_images(gen, frc_x_, frc_y_, value)        \n",
    "        \n",
    "        return gen_res, mean_wasserstein_dist\n",
    "    \n",
    "    def treat_edges(self, d_ori):\n",
    "        # binarize generated images\n",
    "        d_ori = np.squeeze(d_ori)\n",
    "        d_bin = Utility_topo.binarize_data(d_ori, self.watershed)\n",
    "\n",
    "        # compute persistent homology for each image\n",
    "        tsfm_list                 = Utility_topo.dist_trfm_batch(d_bin)\n",
    "        bx, by, dx, dy, pd        = Utility_topo.compute_dist_homology(d_ori.shape, tsfm_list, self.pc, 1, self.debug)\n",
    "        target_ind                = Utility_topo.topo_filter_retindex(pd, self.topo_threshold)\n",
    "        bnd_res, hcy_res, red_res = Utility_topo.compute_bnd_red_cv_batch(d_bin)\n",
    "        fix_x, fix_y, crtB_dt     = self.detection_fix_points(bx, by, pd, target_ind, bnd_res, red_res, d_ori.shape[1:3])    \n",
    "#         loss                      = self.compute_topo_loss(d_ori, fix_x, fix_y, crtB_dt)\n",
    "#         return np.mean(loss)\n",
    "        d_ori = np.expand_dims(self.plot_on_images(d_ori, fix_x, fix_y, -1.0), axis=1)\n",
    "        return d_ori\n",
    "        \n",
    "    def persimg_batch(self, d, binarize=False):\n",
    "        '''\n",
    "        Compute persistence images for the input batch.\n",
    "        ===== inputs\n",
    "        d: input images, if binarize=False, d should have value EITHER 0 OR 255\n",
    "           (binary output from binarize_data() function)\n",
    "        dim: dimension to extract topological information\n",
    "        debug/old_form: refer to Utility_topo.compute_dist_homology\n",
    "        binarize: if to binarize d\n",
    "        '''\n",
    "        if binarize:\n",
    "            d_bin = Utility_topo.binarize_data(d, self.watershed)\n",
    "        else:\n",
    "            d_bin = d\n",
    "        tsfm_list = Utility_topo.dist_trfm_batch(d_bin)\n",
    "        \n",
    "        tsfm_list          = Utility_topo.dist_trfm_batch(d_bin)\n",
    "        bx, by, dx, dy, pd = Utility_topo.compute_dist_homology(d_bin.shape, tsfm_list, self.pc, 1, self.debug)\n",
    "        pims               = self.persimg.pim_batch(pd)\n",
    "        return pims\n",
    "    \n",
    "    def pd_batch(self, d, dim, debug=False, old_form=False, binarize=False, disttrfm=True):\n",
    "        '''\n",
    "        Compute persistence homology for the input batch.\n",
    "        ===== inputs\n",
    "        d: input images, should be numpy array NOT list, if binarize=False,\n",
    "           d should have value EITHER 0 OR 255 (binary output from binarize_data() function)\n",
    "        dim: dimension to extract topological information\n",
    "        debug/old_form: refer to Utility_topo.compute_dist_homology\n",
    "        binarize: if to binarize d\n",
    "        '''\n",
    "        if binarize:\n",
    "            d_bin = Utility_topo.binarize_data(d, self.watershed)\n",
    "        else:\n",
    "            d_bin = d\n",
    "            \n",
    "        if disttrfm:\n",
    "            tsfm_list = Utility_topo.dist_trfm_batch(d_bin)\n",
    "        else:\n",
    "            tsfm_list = Utility_general.flatten_image_batch(d_bin)\n",
    "        \n",
    "        if old_form:\n",
    "            if debug:\n",
    "                birth_x_, birth_y_, death_x_, death_y_, pd_, bnd_, red_ = Utility_topo.compute_dist_homology(\n",
    "                d_bin.shape, tsfm_list, self.pc, dim, debug=True, old_form=True)\n",
    "                return birth_x_, birth_y_, death_x_, death_y_, pd_, bnd_, red_\n",
    "            else:\n",
    "                birth_x_, birth_y_, death_x_, death_y_, pd_ = Utility_topo.compute_dist_homology(\n",
    "                d_bin.shape, tsfm_list, self.pc, dim, debug=False, old_form=True)\n",
    "                return birth_x_, birth_y_, death_x_, death_y_, pd_\n",
    "        else:\n",
    "            if debug:\n",
    "                B_, D_, PD_, bnd_ph, red_ph = Utility_topo.compute_dist_homology(\n",
    "                d_bin.shape, tsfm_list, self.pc, dim, debug=True, old_form=False)\n",
    "                return B_, D_, PD_, tsfm_list, bnd_ph, red_ph\n",
    "            else:\n",
    "                B_, D_, PD_ = Utility_topo.compute_dist_homology(\n",
    "                d_bin.shape, tsfm_list, self.pc, dim, debug=False, old_form=False)\n",
    "                return B_, D_, PD_, tsfm_list\n",
    "    \n",
    "    def plot_on_images(self, images, x, y, value):\n",
    "        '''\n",
    "        plot coordinates on the images\n",
    "        ===== inputs\n",
    "        images: image batch, batch_size * [images]\n",
    "        x/y: batch_size * [integers]\n",
    "        '''\n",
    "        d = copy.copy(np.squeeze(images))\n",
    "        bat_size = d.shape[0]\n",
    "        for i in range(bat_size):\n",
    "            for j in range(len(x[i])):\n",
    "                d[i][y[i][j]][x[i][j]] = value\n",
    "        return d\n",
    "    \n",
    "    def fd_cycle_distance(self, folder_A, folder_B, ext, normalize=True, topothresh=-1.0, disttrfm=False):\n",
    "        '''\n",
    "        folder_A: path to the reference folder\n",
    "        folder_B: path to the target folder\n",
    "        if folder_A equals to folder_B, program will save the second load\n",
    "        '''             \n",
    "        %run cyckernel/Cyckernel.ipynb\n",
    "        \n",
    "        img_batch = Utility_general.read_image_subset(folder_A, ext, 1.0, shuffle=False)\n",
    "        img_batch = np.stack(img_batch)\n",
    "        _, _, PDA, _, bnd_phA, _ = self.pd_batch(img_batch, 1, debug=True, old_form=False, binarize=False, disttrfm=disttrfm)\n",
    "        if topothresh > 0.0:\n",
    "            bnd_phA = Utility_topo.topo_filter_retmat_bndorred_mul(bnd_phA, PDA, 1.0)\n",
    "       \n",
    "        if folder_A == folder_B:\n",
    "            kernel  = CycleKernel(sigma=10.).fit(bnd_phA)\n",
    "            cycdist = kernel.transform(bnd_phA)\n",
    "        else:\n",
    "            img_batch = Utility_general.read_image_subset(folder_B, ext, 1.0, shuffle=False)\n",
    "            img_batch = np.stack(img_batch)\n",
    "            _, _, PDB, _, bnd_phB, _ = self.pd_batch(img_batch, 1, debug=True, old_form=False, binarize=False, disttrfm=disttrfm)\n",
    "            if topothresh > 0.0:\n",
    "                bnd_phB = Utility_topo.topo_filter_retmat_bndorred_mul(bnd_phB, PDB, 1.0)\n",
    "            kernel  = CycleKernel(sigma=10.).fit(bnd_phA)\n",
    "            cycdist = kernel.transform(bnd_phB)\n",
    "            \n",
    "        if normalize:\n",
    "            column_ = cycdist.shape[0]\n",
    "            for i in range(column_):\n",
    "                cycdist[i,:] = cycdist[i,:] / np.linalg.norm(cycdist[i,:]) * 10\n",
    "        \n",
    "        return cycdist\n",
    "    \n",
    "    def fd_wasserstein_distance(self, folder_A, folder_B, ext, dim, wassertein_dist,\n",
    "        topothresh=-1.0, binarize=False, disttrfm=False):\n",
    "        '''\n",
    "        folder_A: path to the target folder\n",
    "        folder_B: path to the reference folder\n",
    "        Note folder order is REVERSE of fd_cycle_distance function!!\n",
    "        ext: extension of the images like \"png\"\n",
    "        dim: dimension of the topology features, integer\n",
    "        wasserstein_dist: 1.0 or 2.0\n",
    "        binarize: if to binarize input images to 0 OR 255\n",
    "        topothresh: topo threshold\n",
    "        project2dim: if to project 2d persistence dot to birth / death\n",
    "        '''       \n",
    "        img_batch = Utility_general.read_image_subset(folder_A, ext, 1.0, shuffle=False)\n",
    "        img_batch = np.stack(img_batch)\n",
    "        _, _, PD1, _ = self.pd_batch(img_batch, dim, debug=False, old_form=False, binarize=binarize, disttrfm=disttrfm)\n",
    "        if topothresh > 0.0:\n",
    "            PD1 = Utility_topo.topo_filter_retmat(PD1, topothresh)\n",
    "        if self.project2dim >= 0:\n",
    "            PD1 = Utility_topo.extract_dim_from_list(PD1, self.project2dim)\n",
    "            \n",
    "        if folder_A == folder_B:\n",
    "            dist, G = Utility_general.wasserstein_set_distance(PD1, PD1, wassertein_dist)\n",
    "        else:\n",
    "            img_batch = Utility_general.read_image_subset(folder_B, ext, 1.0, shuffle=False)\n",
    "            img_batch = np.stack(img_batch)\n",
    "            _, _, PD2, _ = self.pd_batch(img_batch, dim, debug=False, old_form=False, binarize=binarize, disttrfm=disttrfm)\n",
    "            if topothresh > 0.0:\n",
    "                PD2 = Utility_topo.topo_filter_retmat(PD2, topothresh)\n",
    "            if self.project2dim >= 0:\n",
    "                PD2 = Utility_topo.extract_dim_from_list(PD2, self.project2dim)\n",
    "            dist, G = Utility_general.wasserstein_set_distance(PD1, PD2, wassertein_dist)\n",
    "        \n",
    "        return dist      \n",
    "        \n",
    "    def detection_fix_points(self, bx, by, pd, ind, bnd_res, red_res, shape):\n",
    "        bat_size = len(ind)\n",
    "        fix_x    = [None] * bat_size\n",
    "        fix_y    = [None] * bat_size\n",
    "        crt_birth_distrfm_val = [None] * bat_size\n",
    "        kernel = np.ones((self.hole_kernel_r, self.hole_kernel_r), np.uint8)\n",
    "        \n",
    "        for i in range(bat_size):\n",
    "            set_x = []\n",
    "            set_y = []\n",
    "            crt_b_dt_val = []\n",
    "            good_section_record = []\n",
    "            for idx in ind[i]:\n",
    "                countour_idx = Utility_topo.return_countour_with_p_inside(bnd_res[i], (bx[i][idx], by[i][idx]))\n",
    "                if countour_idx >= 0:\n",
    "                    section_label = red_res[i][1][by[i][idx]][bx[i][idx]]\n",
    "                    if section_label not in good_section_record:\n",
    "                        hole_test = Utility_topo.dangling_edge_test(section_label, red_res[i],\n",
    "                                    shape, kernel, self.hole_iterations, self.hole_bordwidth)\n",
    "                        if hole_test > self.hole_threshold:\n",
    "                            good_section_record.append(section_label)\n",
    "                    if section_label in good_section_record:\n",
    "                        pts_x, pts_y = Utility_general.find_closest_N_points((bx[i][idx], by[i][idx]),\n",
    "                                       bnd_res[i][countour_idx], self.pts_to_fix)\n",
    "                        set_x = set_x + pts_x\n",
    "                        set_y = set_y + pts_y\n",
    "                        crt_b_dt_val.append(pd[i][idx][0])\n",
    "            fix_x[i] = set_x\n",
    "            fix_y[i] = set_y\n",
    "            crt_birth_distrfm_val[i] = crt_b_dt_val\n",
    "        return fix_x, fix_y, crt_birth_distrfm_val\n",
    "    \n",
    "    def compute_topo_loss(self, data_origin, fix_x, fix_y, crt_birth_distrfm_val):\n",
    "        bat_size = data_origin.shape[0]\n",
    "        loss = [0.0] * bat_size\n",
    "        \n",
    "        for i in range(bat_size):\n",
    "            l_ = 0.0\n",
    "            for j in range(len(fix_x[i])):\n",
    "                cur_val = crt_birth_distrfm_val[i][int(j/self.pts_to_fix)]\n",
    "                l_ = l_ + (data_origin[i][fix_y[i][j]][fix_x[i][j]] - (-1.0)) * cur_val\n",
    "            loss[i] = l_\n",
    "        return loss\n",
    "    \n",
    "    def test(self, d, device):\n",
    "        c = torch.randn([128, 1, 64, 64]).to(device)\n",
    "        loss = torch.abs(c - d).mean()\n",
    "        return loss\n",
    "    \n",
    "    def return_tp_weight(self):\n",
    "        return self.tp_loss_weight\n",
    "    \n",
    "    def return_target_dim(self):\n",
    "        return self.target_dim\n",
    "    \n",
    "    def blind(self):\n",
    "        return self.blind_force\n",
    "    \n",
    "class PersImg_(object):\n",
    "    \n",
    "    def __init__(self, params, verbose):\n",
    "        self.pim = PersImage(spread=params[\"spread\"], pixels=params[\"pixels\"], verbose=verbose)\n",
    "        \n",
    "    def pim_single(self, dgm):\n",
    "        return self.pim.transform(dgm)\n",
    "    \n",
    "    def pim_batch(self, phc_pd):\n",
    "        num_ = len(phc_pd)\n",
    "        dgms = Utility_topo.convert_phc_pd_2_persim_batch(phc_pd, np.arange(num_))\n",
    "        pim_list = [None] * num_\n",
    "        for i in range(num_):\n",
    "            pim_list[i] = np.expand_dims(self.pim_single(dgms[i]), 0)\n",
    "        pim_list = np.concatenate(pim_list, axis=0)\n",
    "        return pim_list\n",
    "    \n",
    "class LPSolver_(object):\n",
    "    \n",
    "    def __init__(self, M, N, show_progress):\n",
    "        '''\n",
    "        Find a match so that the distance is minimized through\n",
    "        linear programming. Distance matrix should be M X N.\n",
    "        Samples on left are targets, samples on top are database.\n",
    "        '''\n",
    "        solvers.options['show_progress'] = show_progress\n",
    "        solvers.options['glpk'] = {'msg_lev': 'GLP_MSG_OFF'}\n",
    "        \n",
    "        A_ = spmatrix(1.0, range(N), [0]*N, (N, M))\n",
    "        for i in range(1, M):\n",
    "            A_sub = spmatrix(1.0, range(N), [i]*N, (N, M))\n",
    "            A_    = sparse([A_, A_sub])\n",
    "            \n",
    "        D_sub = spmatrix(-1.0, range(N), range(N), (N, N))\n",
    "        D_ = D_sub\n",
    "        for i in range(1, M):\n",
    "            D_ = sparse([D_, D_sub])          \n",
    "        self.A = sparse([[A_], [D_]])\n",
    "        \n",
    "        cr = matrix([-1.0 / M] * M)\n",
    "        cf = matrix([1.0 / N] * N)\n",
    "        self.c = matrix([cr, cf])\n",
    "           \n",
    "        # determine initial point\n",
    "        self.pStart = {}\n",
    "        self.pStart['x'] = matrix([matrix([1.0]*M),matrix([-1.0]*N)])\n",
    "        self.pStart['s'] = matrix([1.0]*(M + N))\n",
    "        self.M           = M\n",
    "        self.N           = N\n",
    "        \n",
    "    def approx_OT(self, sol):\n",
    "        '''\n",
    "        Each sample on the left has a best match.\n",
    "        '''\n",
    "        ResMat = np.array(sol['z']).reshape((self.M, self.N))\n",
    "        mapping = np.argmax(ResMat, axis=1).astype(np.int64)\n",
    "        return mapping\n",
    "        \n",
    "    def Wasserstein_LP(self, dist):\n",
    "        assert(dist.shape[0] == self.M and dist.shape[1] == self.N)\n",
    "        h = matrix(dist.astype(np.double).flatten())\n",
    "        sol = solvers.lp(self.c, self.A, h, primalstart=self.pStart, solver='glpk')\n",
    "        self.pStart['x'] = sol['x']\n",
    "        self.pStart['s'] = sol['s']\n",
    "        return sol\n",
    "    \n",
    "    def linear_program_(self, dist, G):\n",
    "        solution = self.Wasserstein_LP(dist)\n",
    "        mapping  = self.approx_OT(solution)\n",
    "        dist_    = [0.] * self.M\n",
    "        G_       = [None] * self.M\n",
    "        for i in range(len(mapping)):\n",
    "            dist_[i] = dist[i, mapping[i]]\n",
    "            G_[i]    = G[i][mapping[i]]\n",
    "        return mapping, dist_, G_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c427d358109a68739b592cd7c9436d87512ddabfb8edf4c5359ed8348eaf8cbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
